==> generated_models/bert-base-multilingual-cased_lr1e-05_bs16_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr1e-05_bs16_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.806	0.824	0.819	0.821	0.82	0.822	0.822	0.818	0.818	0.822
val_loss	0.487	0.466	0.538	0.55	0.614	0.701	0.924	0.982	1.099	1.141
tra_loss	0.584	0.443	0.356	0.29	0.238	0.204	0.178	0.155	0.133	0.115
Best F1 on evaluation is 0.824
==> generated_models/bert-base-multilingual-cased_lr1e-05_bs32_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr1e-05_bs32_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.808	0.822	0.818	0.823	0.826	0.818	0.823	0.824	0.818	0.825
val_loss	0.498	0.458	0.494	0.524	0.555	0.596	0.692	0.719	0.812	0.853
tra_loss	0.589	0.448	0.365	0.3	0.247	0.206	0.171	0.146	0.126	0.114
Best F1 on evaluation is 0.826
==> generated_models/bert-base-multilingual-cased_lr1e-05_bs8_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr1e-05_bs8_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.802	0.828	0.814	0.81	0.822	0.815	0.812	0.821	0.817	0.822
val_loss	0.496	0.455	0.638	0.74	0.783	0.985	1.126	1.2	1.32	1.348
tra_loss	0.593	0.462	0.396	0.358	0.318	0.276	0.225	0.181	0.143	0.115
Best F1 on evaluation is 0.828
==> generated_models/bert-base-multilingual-cased_lr1e-06_bs16_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr1e-06_bs16_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.752	0.792	0.797	0.804	0.803	0.805	0.808	0.811	0.813	0.811
val_loss	0.607	0.529	0.526	0.519	0.511	0.51	0.504	0.507	0.509	0.509
tra_loss	0.705	0.576	0.532	0.504	0.484	0.466	0.454	0.444	0.437	0.433
Best F1 on evaluation is 0.813
==> generated_models/bert-base-multilingual-cased_lr1e-06_bs32_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr1e-06_bs32_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.738	0.772	0.787	0.796	0.799	0.797	0.802	0.799	0.802	0.803
val_loss	0.629	0.56	0.55	0.53	0.525	0.523	0.511	0.514	0.513	0.513
tra_loss	0.736	0.602	0.559	0.531	0.512	0.499	0.486	0.479	0.473	0.469
Best F1 on evaluation is 0.803
==> generated_models/bert-base-multilingual-cased_lr1e-06_bs8_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr1e-06_bs8_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.769	0.799	0.792	0.804	0.814	0.808	0.812	0.813	0.817	0.815
val_loss	0.591	0.518	0.555	0.534	0.527	0.53	0.541	0.548	0.559	0.558
tra_loss	0.69	0.562	0.517	0.487	0.465	0.449	0.435	0.426	0.418	0.414
Best F1 on evaluation is 0.817
==> generated_models/bert-base-multilingual-cased_lr2e-05_bs16_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr2e-05_bs16_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.801	0.819	0.811	0.821	0.819	0.816	0.811	0.821	0.819	0.816
val_loss	0.499	0.464	0.534	0.63	0.672	0.796	1.089	1.109	1.231	1.33
tra_loss	0.596	0.453	0.359	0.282	0.226	0.188	0.157	0.122	0.091	0.067
Best F1 on evaluation is 0.821
==> generated_models/bert-base-multilingual-cased_lr2e-05_bs32_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr2e-05_bs32_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.801	0.83	0.813	0.823	0.824	0.813	0.816	0.817	0.819	0.819
val_loss	0.498	0.449	0.495	0.543	0.573	0.693	0.861	0.924	1.093	1.156
tra_loss	0.583	0.435	0.339	0.261	0.199	0.153	0.12	0.095	0.077	0.062
Best F1 on evaluation is 0.83
==> generated_models/bert-base-multilingual-cased_lr2e-05_bs8_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr2e-05_bs8_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.793	0.813	0.806	0.813	0.817	0.805	0.813	0.827	0.819	0.823
val_loss	0.534	0.494	0.531	0.648	0.769	0.976	1.082	1.122	1.269	1.405
tra_loss	0.626	0.499	0.425	0.376	0.334	0.281	0.222	0.163	0.113	0.075
Best F1 on evaluation is 0.827
==> generated_models/bert-base-multilingual-cased_lr2e-06_bs16_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr2e-06_bs16_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.779	0.811	0.81	0.816	0.821	0.815	0.817	0.819	0.82	0.82
val_loss	0.554	0.494	0.5	0.496	0.495	0.508	0.51	0.519	0.53	0.532
tra_loss	0.651	0.527	0.476	0.441	0.414	0.389	0.371	0.357	0.345	0.339
Best F1 on evaluation is 0.821
==> generated_models/bert-base-multilingual-cased_lr2e-06_bs32_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr2e-06_bs32_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.768	0.8	0.802	0.813	0.809	0.807	0.814	0.814	0.817	0.817
val_loss	0.581	0.511	0.514	0.495	0.501	0.503	0.495	0.503	0.505	0.505
tra_loss	0.676	0.549	0.502	0.469	0.445	0.426	0.409	0.399	0.389	0.383
Best F1 on evaluation is 0.817
==> generated_models/bert-base-multilingual-cased_lr2e-06_bs8_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr2e-06_bs8_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.79	0.812	0.809	0.822	0.819	0.82	0.825	0.826	0.827	0.828
val_loss	0.542	0.489	0.541	0.535	0.575	0.597	0.657	0.697	0.732	0.735
tra_loss	0.633	0.513	0.461	0.426	0.401	0.384	0.37	0.361	0.353	0.348
Best F1 on evaluation is 0.828
==> generated_models/bert-base-multilingual-cased_lr5e-06_bs16_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr5e-06_bs16_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.804	0.821	0.821	0.826	0.824	0.824	0.823	0.821	0.821	0.825
val_loss	0.5	0.463	0.507	0.498	0.534	0.601	0.665	0.697	0.781	0.798
tra_loss	0.601	0.468	0.399	0.345	0.301	0.265	0.239	0.219	0.203	0.193
Best F1 on evaluation is 0.826
==> generated_models/bert-base-multilingual-cased_lr5e-06_bs32_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr5e-06_bs32_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.794	0.818	0.823	0.822	0.821	0.814	0.825	0.825	0.829	0.829
val_loss	0.528	0.472	0.494	0.489	0.519	0.539	0.553	0.573	0.593	0.605
tra_loss	0.615	0.486	0.422	0.374	0.334	0.303	0.275	0.254	0.237	0.227
Best F1 on evaluation is 0.829
==> generated_models/bert-base-multilingual-cased_lr5e-06_bs8_epochs10_l=en/metrics.csv <==
bert-base-multilingual-cased_lr5e-06_bs8_epochs10_l=en
epoch	1	2	3	4	5	6	7	8	9	10
val_f1	0.808	0.822	0.809	0.82	0.821	0.817	0.819	0.822	0.821	0.82
val_loss	0.493	0.488	0.605	0.654	0.745	0.835	0.958	1.011	1.101	1.129
tra_loss	0.596	0.469	0.407	0.372	0.345	0.319	0.291	0.264	0.236	0.218
Best F1 on evaluation is 0.822